{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlKvl6JlZID7",
        "outputId": "271f26bd-9b74-4d30-8e80-391395fdff0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q mediapipe-model-maker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoWQLeN7ZJkL",
        "outputId": "e9930e6c-9a57-4929-e238-f77d0b956c1f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from mediapipe_model_maker import gesture_recognizer\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaqVmvWGZKX0",
        "outputId": "20f16aa8-9be5-419b-e250-004264faf3d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lP1DiTlKZLRg"
      },
      "outputs": [],
      "source": [
        "base_path = \"/content/drive/MyDrive/Colab Notebooks/garudahacks-ai\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6nIaSO1ZNEH",
        "outputId": "577b6d0c-4f95-4b38-865b-3b1b1cb350c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/garudahacks-ai/asl_dataset\n"
          ]
        }
      ],
      "source": [
        "images_path = os.path.join(base_path, 'asl_dataset')\n",
        "print(images_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iKvbuVVZQCK",
        "outputId": "b92a453f-d7c4-4c7d-9490-f3535a10542b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels :  ['4', '9', '6', '0', '8', '3', '1', '5', '2', '7', 'h', 'i', 'd', 'f', 'b', 'a', 'j', 'g', 'c', 'e', 'o', 'l', 'k', 'm', 'n', 'none', 's', 'r', 'q', 'p', 'y', 'u', 'w', 'v', 'z', 't', 'x']\n",
            "Len Labels :  37\n"
          ]
        }
      ],
      "source": [
        "labels = os.listdir(images_path)\n",
        "\n",
        "\n",
        "print('Labels : ', labels)\n",
        "print('Len Labels : ', len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJEtpoicZRIS",
        "outputId": "aa912569-e2b2-41b1-961a-ea017b317216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Images :  2515\n"
          ]
        }
      ],
      "source": [
        "total_images = 0\n",
        "for label in labels:\n",
        "    label_dir = os.path.join(images_path, label)\n",
        "    file_names = os.listdir(label_dir)\n",
        "\n",
        "    total_images += len(file_names)\n",
        "\n",
        "    for index, file_name in enumerate(file_names):\n",
        "        file_path = os.path.join(label_dir, file_name)\n",
        "        new_file_path = os.path.join(label_dir, f'{index}.jpg')\n",
        "        if file_path != new_file_path:\n",
        "            os.rename(file_path, new_file_path)\n",
        "        try:\n",
        "            with Image.open(new_file_path) as img:\n",
        "                if img.width != 400 or img.height != 400:\n",
        "                    print('Invalid Image : ', new_file_path)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "\n",
        "print('Total Images : ', total_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frM8iF2YZSF4",
        "outputId": "6d5b6fc5-537c-413f-fcd1-c146891b1b2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://storage.googleapis.com/mediapipe-assets/palm_detection_full.tflite to /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n",
            "Downloading https://storage.googleapis.com/mediapipe-assets/hand_landmark_full.tflite to /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://storage.googleapis.com/mediapipe-assets/gesture_embedder.tar.gz to /tmp/model_maker/gesture_recognizer/gesture_embedder\n"
          ]
        }
      ],
      "source": [
        "data = gesture_recognizer.Dataset.from_folder(\n",
        "    dirname=images_path,\n",
        "    hparams=gesture_recognizer.HandDataPreprocessingParams(),\n",
        ")\n",
        "train_data, rest_data = data.split(0.8)\n",
        "validation_data, test_data = rest_data.split(0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1rrntWHZTSj",
        "outputId": "6354c6bd-8807-40a7-e251-241d3ef4973d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hand_embedding (InputLayer  [(None, 128)]             0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 128)               512       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 128)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " custom_gesture_recognizer_  (None, 37)                4773      \n",
            " out (Dense)                                                     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5285 (20.64 KB)\n",
            "Trainable params: 5029 (19.64 KB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "562/562 [==============================] - 13s 13ms/step - loss: 2.4082 - categorical_accuracy: 0.2553 - val_loss: 0.9877 - val_categorical_accuracy: 0.5603 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "562/562 [==============================] - 11s 20ms/step - loss: 1.4092 - categorical_accuracy: 0.5000 - val_loss: 0.5173 - val_categorical_accuracy: 0.7447 - lr: 9.9000e-04\n",
            "Epoch 3/10\n",
            "562/562 [==============================] - 9s 15ms/step - loss: 1.0593 - categorical_accuracy: 0.5943 - val_loss: 0.3385 - val_categorical_accuracy: 0.8440 - lr: 9.8010e-04\n",
            "Epoch 4/10\n",
            "562/562 [==============================] - 9s 16ms/step - loss: 0.8922 - categorical_accuracy: 0.6441 - val_loss: 0.2519 - val_categorical_accuracy: 0.8652 - lr: 9.7030e-04\n",
            "Epoch 5/10\n",
            "562/562 [==============================] - 8s 15ms/step - loss: 0.7622 - categorical_accuracy: 0.6957 - val_loss: 0.2131 - val_categorical_accuracy: 0.8652 - lr: 9.6060e-04\n",
            "Epoch 6/10\n",
            "562/562 [==============================] - 9s 16ms/step - loss: 0.6877 - categorical_accuracy: 0.7313 - val_loss: 0.1797 - val_categorical_accuracy: 0.8652 - lr: 9.5099e-04\n",
            "Epoch 7/10\n",
            "562/562 [==============================] - 7s 12ms/step - loss: 0.6294 - categorical_accuracy: 0.7456 - val_loss: 0.1691 - val_categorical_accuracy: 0.8723 - lr: 9.4148e-04\n",
            "Epoch 8/10\n",
            "562/562 [==============================] - 7s 12ms/step - loss: 0.5845 - categorical_accuracy: 0.7544 - val_loss: 0.1431 - val_categorical_accuracy: 0.8865 - lr: 9.3207e-04\n",
            "Epoch 9/10\n",
            "562/562 [==============================] - 10s 18ms/step - loss: 0.5469 - categorical_accuracy: 0.7705 - val_loss: 0.1512 - val_categorical_accuracy: 0.8723 - lr: 9.2274e-04\n",
            "Epoch 10/10\n",
            "562/562 [==============================] - 9s 16ms/step - loss: 0.5055 - categorical_accuracy: 0.7883 - val_loss: 0.1374 - val_categorical_accuracy: 0.8865 - lr: 9.1352e-04\n"
          ]
        }
      ],
      "source": [
        "hparams = gesture_recognizer.HParams(export_dir=\"asl_model\")\n",
        "options = gesture_recognizer.GestureRecognizerOptions(hparams=hparams)\n",
        "model = gesture_recognizer.GestureRecognizer.create(\n",
        "    train_data=train_data,\n",
        "    validation_data=validation_data,\n",
        "    options=options\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALz7uHpiZUNa",
        "outputId": "01d399bd-c04b-475a-edd6-92372dcd2106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "141/141 [==============================] - 4s 4ms/step - loss: 0.2626 - categorical_accuracy: 0.8298\n",
            "Test loss:0.2625753879547119, Test accuracy:0.8297872543334961\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(test_data, batch_size=1)\n",
        "print(f\"Test loss:{loss}, Test accuracy:{acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ysyCWQPaWt0",
        "outputId": "8cc4699f-593d-4e82-8751-dfab583fbf14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://storage.googleapis.com/mediapipe-assets/gesture_embedder.tflite to /tmp/model_maker/gesture_recognizer/gesture_embedder.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n",
            "Downloading https://storage.googleapis.com/mediapipe-assets/canned_gesture_classifier.tflite to /tmp/model_maker/gesture_recognizer/canned_gesture_classifier.tflite\n"
          ]
        }
      ],
      "source": [
        "model_name = \"model_2.task\"\n",
        "model.export_model(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "IXjU5yvdZVKD",
        "outputId": "d2c00e7b-6a6d-45ca-b4a8-ff31f89ac06e"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_3fe84922-5d74-424b-8c3b-7c74d247b1b8\", \"model_2.task\", 8477939)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(f\"asl_model/{model_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5UnMvgTZV6L",
        "outputId": "dc35d5ae-fbda-4504-e9ef-0f0cad8b7620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/garudahacks-ai/test.jpg\n"
          ]
        }
      ],
      "source": [
        "test_path = os.path.join(base_path, 'test.jpg')\n",
        "print(test_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUYYIDriZWjG",
        "outputId": "601b4bcc-86bc-474b-a6e3-f137715bf87a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[ 58  54  65]\n",
            "  [ 52  48  59]\n",
            "  [ 47  43  54]\n",
            "  ...\n",
            "  [227 215 197]\n",
            "  [223 211 193]\n",
            "  [223 211 193]]\n",
            "\n",
            " [[ 57  53  64]\n",
            "  [ 53  49  60]\n",
            "  [ 50  46  57]\n",
            "  ...\n",
            "  [227 215 197]\n",
            "  [221 209 191]\n",
            "  [221 209 191]]\n",
            "\n",
            " [[ 57  53  64]\n",
            "  [ 56  52  63]\n",
            "  [ 54  50  61]\n",
            "  ...\n",
            "  [226 214 196]\n",
            "  [226 214 196]\n",
            "  [226 214 196]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 62 110 138]\n",
            "  [ 63 111 139]\n",
            "  [ 64 112 140]\n",
            "  ...\n",
            "  [144 173 182]\n",
            "  [155 184 191]\n",
            "  [155 184 191]]\n",
            "\n",
            " [[ 62 110 138]\n",
            "  [ 63 111 139]\n",
            "  [ 64 112 140]\n",
            "  ...\n",
            "  [144 173 182]\n",
            "  [152 181 188]\n",
            "  [152 181 188]]\n",
            "\n",
            " [[ 62 110 138]\n",
            "  [ 63 111 139]\n",
            "  [ 64 112 140]\n",
            "  ...\n",
            "  [144 173 182]\n",
            "  [149 178 185]\n",
            "  [149 178 185]]]\n"
          ]
        }
      ],
      "source": [
        "img = cv2.imread(test_path)\n",
        "print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUk6OZZDZXTB",
        "outputId": "b68e7f8f-0544-4431-aceb-df98f803ccc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Path :  /content/asl_model/model_2.task\n",
            "Gesture :  [Category(index=-1, score=0.8560377955436707, display_name='', category_name='')]\n",
            "Top Gesture :  Category(index=-1, score=0.8560377955436707, display_name='', category_name='')\n",
            "Gesture recognized:  (0.8560377955436707)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
          ]
        }
      ],
      "source": [
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "\n",
        "model_path = os.path.abspath(f\"asl_model/{model_name}\")\n",
        "print('Model Path : ', model_path)\n",
        "\n",
        "recognizer = vision.GestureRecognizer.create_from_model_path(model_path)\n",
        "\n",
        "image = mp.Image.create_from_file(test_path)\n",
        "\n",
        "recognition_result = recognizer.recognize(image)\n",
        "\n",
        "top_gesture = recognition_result.gestures[0][0]\n",
        "print('Gesture : ', recognition_result.gestures[0])\n",
        "print('Top Gesture : ', top_gesture)\n",
        "print(f\"Gesture recognized: {top_gesture.category_name} ({top_gesture.score})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t71RsyDpZZ6p",
        "outputId": "f50aeb82-2c43-4100-87d1-d89f72436c90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'asl_model/new_model.task': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mv asl_model/new_model.task \"/content/drive/My Drive/Colab Notebooks/garudahacks-pre-ai/\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
